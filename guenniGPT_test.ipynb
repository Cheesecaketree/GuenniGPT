{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"./files/keys.json\", \"r\") as f:\n",
    "    key = json.load(f)\n",
    "\n",
    "openai.api_key = key[\"openai\"]\n",
    "openai.organization = key[\"openai-org\"]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herzlich Willkommen, chopchip2! Schön, dass du dich zu uns in den \"Sphieele\" Kanal verirrt hast. Ich hoffe, du bist bereit für eine wilde Fahrt!\n"
     ]
    }
   ],
   "source": [
    "system_message = {\n",
    "        \"role\": \"system\", \"content\": \"You are a discord bot that greets people joining a voice channel. You get passed name, channel, time and server language. Greet them in a funny and creative way. Keep it short, use the given language, dont use emojis.\"\n",
    "    }\n",
    "\n",
    "messages = [\n",
    "    system_message,\n",
    "    {\"role\": \"user\", \"content\": \"lang=de, chopchip2 joined channel \\\"Sphieele\\\" at 12:00am\"},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = messages,\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message.content\n",
    "\n",
    "print(response_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7TvVMLnNslJ8pmHqlPLWX8d1fgSwG at 0x107387770> JSON: {\n",
       "  \"id\": \"chatcmpl-7TvVMLnNslJ8pmHqlPLWX8d1fgSwG\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687366916,\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Herzlich Willkommen, chopchip2! Sch\\u00f6n, dass du dich zu uns in den \\\"Sphieele\\\" Kanal verirrt hast. Ich hoffe, du bist bereit f\\u00fcr eine wilde Fahrt!\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 83,\n",
       "    \"completion_tokens\": 49,\n",
       "    \"total_tokens\": 132\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "date format should be 'YYYY-MM-DD', received ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m r \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mapi_requestor\u001b[39m.\u001b[39mAPIRequestor()\n\u001b[0;32m----> 2\u001b[0m resp \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m/usage?date\u001b[39;49m\u001b[39m'\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mstart_date\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m2023-06-15\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mend_date\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m2023-06-21\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/Coding/GuenniGPT/.venv/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Coding/GuenniGPT/.venv/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Coding/GuenniGPT/.venv/lib/python3.11/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: date format should be 'YYYY-MM-DD', received "
     ]
    }
   ],
   "source": [
    "r = openai.api_requestor.APIRequestor()\n",
    "resp = r.request(\"GET\", '/usage?date=2021-10-01', {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'aggregation_timestamp': 1687349700,\n",
       "   'n_requests': 13,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 13,\n",
       "   'n_context_tokens_total': 1156,\n",
       "   'n_generated': 13,\n",
       "   'n_generated_tokens_total': 446},\n",
       "  {'aggregation_timestamp': 1687350000,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 93,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 60},\n",
       "  {'aggregation_timestamp': 1687352100,\n",
       "   'n_requests': 9,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 9,\n",
       "   'n_context_tokens_total': 755,\n",
       "   'n_generated': 9,\n",
       "   'n_generated_tokens_total': 492},\n",
       "  {'aggregation_timestamp': 1687352400,\n",
       "   'n_requests': 3,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 3,\n",
       "   'n_context_tokens_total': 248,\n",
       "   'n_generated': 3,\n",
       "   'n_generated_tokens_total': 136},\n",
       "  {'aggregation_timestamp': 1687359600,\n",
       "   'n_requests': 3,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'text-davinci:003',\n",
       "   'n_context': 3,\n",
       "   'n_context_tokens_total': 618,\n",
       "   'n_generated': 3,\n",
       "   'n_generated_tokens_total': 82},\n",
       "  {'aggregation_timestamp': 1687359600,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'edit',\n",
       "   'snapshot_id': 'text-davinci-edit:001',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 248,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 468},\n",
       "  {'aggregation_timestamp': 1687359900,\n",
       "   'n_requests': 6,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 6,\n",
       "   'n_context_tokens_total': 477,\n",
       "   'n_generated': 6,\n",
       "   'n_generated_tokens_total': 453},\n",
       "  {'aggregation_timestamp': 1687359900,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-4-0314',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 90,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 64},\n",
       "  {'aggregation_timestamp': 1687360200,\n",
       "   'n_requests': 8,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-4-0314',\n",
       "   'n_context': 8,\n",
       "   'n_context_tokens_total': 807,\n",
       "   'n_generated': 8,\n",
       "   'n_generated_tokens_total': 473},\n",
       "  {'aggregation_timestamp': 1687360800,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 170,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 82},\n",
       "  {'aggregation_timestamp': 1687361100,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 85,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 42},\n",
       "  {'aggregation_timestamp': 1687361700,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 174,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 104},\n",
       "  {'aggregation_timestamp': 1687362000,\n",
       "   'n_requests': 3,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 3,\n",
       "   'n_context_tokens_total': 261,\n",
       "   'n_generated': 3,\n",
       "   'n_generated_tokens_total': 129},\n",
       "  {'aggregation_timestamp': 1687362300,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 87,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 47},\n",
       "  {'aggregation_timestamp': 1687362600,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 87,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 51},\n",
       "  {'aggregation_timestamp': 1687362900,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 86,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 59},\n",
       "  {'aggregation_timestamp': 1687363200,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 172,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 124},\n",
       "  {'aggregation_timestamp': 1687363500,\n",
       "   'n_requests': 6,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 6,\n",
       "   'n_context_tokens_total': 517,\n",
       "   'n_generated': 6,\n",
       "   'n_generated_tokens_total': 358},\n",
       "  {'aggregation_timestamp': 1687363800,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 86,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 60},\n",
       "  {'aggregation_timestamp': 1687364400,\n",
       "   'n_requests': 4,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 4,\n",
       "   'n_context_tokens_total': 362,\n",
       "   'n_generated': 4,\n",
       "   'n_generated_tokens_total': 215},\n",
       "  {'aggregation_timestamp': 1687364400,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-4-0314',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 93,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 31},\n",
       "  {'aggregation_timestamp': 1687364700,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 184,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 80},\n",
       "  {'aggregation_timestamp': 1687365000,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 184,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 86},\n",
       "  {'aggregation_timestamp': 1687365300,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 184,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 98},\n",
       "  {'aggregation_timestamp': 1687365600,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 92,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 31},\n",
       "  {'aggregation_timestamp': 1687365900,\n",
       "   'n_requests': 1,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 1,\n",
       "   'n_context_tokens_total': 90,\n",
       "   'n_generated': 1,\n",
       "   'n_generated_tokens_total': 43},\n",
       "  {'aggregation_timestamp': 1687366800,\n",
       "   'n_requests': 2,\n",
       "   'operation': 'completion',\n",
       "   'snapshot_id': 'gpt-3.5-turbo-0301',\n",
       "   'n_context': 2,\n",
       "   'n_context_tokens_total': 166,\n",
       "   'n_generated': 2,\n",
       "   'n_generated_tokens_total': 71}],\n",
       " 'ft_data': [],\n",
       " 'dalle_api_data': [],\n",
       " 'whisper_api_data': [],\n",
       " 'current_usage_usd': 0.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp[0].data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
